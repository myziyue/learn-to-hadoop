第二章 关于MapReduce
============

## Hadoop单节点安装配置

1、配置环境

1.1、软件包
sun jdk  或 openjdk： 1.7 

1.2、安装必须软件包：

```
# yum install ssh rsync

# rpm -ivh jdk-7u79-linux-x64.rpm
```

1.3、配置java环境

```
# vim /etc/profile
export JAVA_HOME=/usr/java/latest
export JRE_HOME=$JAVA_HOME/jre
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib
```

```
# vim hadoop_home/etc/hadoop/hadoop_env.sh
export JAVA_HOME=/usr/java/latest
或者
export JAVA_HOME=/usr/lib/jvm/jre-1.7.0-openjdk.x86_64
```

2、单节点配置文件配置
```
# vim hadoop_home/etc/hadoop/core-site.xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

```
# vim hadoop_home/etc/hadoop/hdfs-site.xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

3、设置ssh免密登陆

```
# ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
# cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
# chmod 0600 ~/.ssh/authorized_keys
```

4、测试环境
    1.格式化文件系统
    
```
$ bin/hdfs namenode -format
```

    2. 开启 NameNode 服务和 DataNode 服务

```
$ sbin/start-dfs.sh
```

    3. 用浏览器浏览 NameNode，默认地址如下：

http://localhost:50070/

    4. 创建HDFS所需的目录

```
$ bin/hdfs dfs -mkdir /user
$ bin/hdfs dfs -mkdir /user/<username>
```

    5. 复制输入文件到目标文件系统：

```
$ bin/hdfs dfs -put etc/hadoop input
```

    6.运行hadoop提供的案例

```
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep input output 'dfs[a-z.]+'
```

    7. 将运算结果获取到本地
    
```
$ bin/hdfs dfs -get output output
$ cat output/*
```
    或者在目标系统浏览
```
$ bin/hdfs dfs -cat output/*
```

    8. 停止DFS服务

```
$ sbin/stop-dfs.sh
```

## 使用Hadoop来分析数据

1. MapReduce任务过程分为两个处理阶段：map阶段和reduce阶段。map阶段是数据准备阶段。reduce是数据处理阶段。

2. 案例:

    - 编译并打包，案例代码：`learn-to-hadoop/src/com/myziyue/hadoop/ch02`
    
    - 将输入输入拷贝到hadoop目录下：`learn-to-hadoop/input/`
    
    - 打包后的jar包，拷贝到hadoop目录里，执行下面的指令：
    
    ```
    $ export HADOOP_CLASSPATH=learn-to-hadoop.jar
    $ ./bin/haddoop com/myziyue/hadoop/ch02/MaxTemperature input/ncdc/sample.txt output
    ```
    
    - 查看输出结果：
    
    ```
    $ cat output/part-00000
    ```

## hadoop逻辑过程可用如下图表示：

![hadoop逻辑过程](./images/hadoop1.png)


## 数据流

MapReduce作业（job）是客户端需要执行的一个工作单元：它包括输入数据、MapReduce程序和配置信息。Hadoop将作业分成若干个小任务（task）来执行，其中包括两类任务：map任务和reduce任务。

有两类节点控制着作业执行过程：一个jobtracker 及一系列tasktracker。jobtracker通过调度tasktracker上运行的任务来协调所有运行在系统上的作业。
tasktracker在运行任务的同时将运行进度报告发送给jobtacker，jobtracker由此记录每项作业任务的整体进度情况。如果其中一个任务失败，jobtracker可以在另外一个tasktracker节点上重新调度该任务。

Hadoop将MapReduce的输入数据划分成等长的小数据块，称为输入分片（input split）或简称"分片"。Hadoop为每个分片构建一个map任务，并由该任务来运行用户自定义的map函数从而处理分片中的每条记录。

最佳的分片的大小英爱与块大小相同：因为它是确保可以存储在单个节点上的最大输入块的大小。

一个reduce任务的完整数据流如下图所示。虚线框表示节点，虚线箭头表示节点内部的数据传输，而实线箭头表示不同节点之间的数据传输。
![一个reduce任务的MapReduce数据流](./images/hadoop2.jpg)

reduce热舞呢的数量并非由输入数据的大小决定，而事实上是独立制定的。

如果有好多个reduce任务，每个map任务就会针对输出进行分区（partition），即为每个reduce任务建一个分区。每个分区有许多键（及其对应的值），但是每个键对应的键/值对记录都在同一个分区中。
分区由用户定义的partition函数控制，但通常用默认的partitioner通过哈希函数来分区，很高效。
![多个reduce任务的数据流](./images/hadoop3.jpg)

## combiner函数

集群上的可用带宽限制了MapReduce作业的数量，因此尽量避免map和reduce任务之间的数据传输是有利的。可以有效减少mapper和reducer之间的数据传输量。

combiner的规则制约着可用的函数类型。














